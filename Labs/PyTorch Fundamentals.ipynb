{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6uoVN0u3LB_"
      },
      "source": [
        "# The material presented in this notebook is for use in Introduction to Deep Learning ECE.685D course, Duke University, Fall 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRqGH8043LCB"
      },
      "source": [
        "* ### Static frameworks such as Theano, Caffe, and TensorFlow require the computational graph to be first declared, compiled, and then executed.\n",
        "* ### This leads to very efficient implementations (in production and mobile settings), it can become very painful during research and development. \n",
        "* ### Modern frameworks such as Chainer, DyNet, and PyTorch implement dynamic computational graphs. These are more flexible, and provide imperative style of coding.\n",
        "* ### We do not need to compile the models before every execution.\n",
        "* ### __PyTorch is a library (framework) which is optimized for tensor manipulation, and it provides a series of packages for deep learning.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtdCbJJZ3LCB"
      },
      "source": [
        "## __Modules and packages in Pytorch__\n",
        "* ### __torch :__  a Tensor library like Numpy, with strong GPU support\n",
        "* ### __torch.autograd :__ an automatic differentiation library that supports all differentiable Tensor operations in torch\n",
        "* ### __torch.nn :__ a neural networks library integrated with autograd\n",
        "* ### __torch.nn.functional :__ implementation of many useful mathematical functions such as Relu, Tanh, and so on.\n",
        "* ### __torch.optim :__ an optimization package to be used with torch.nn with standard optimization methods such as SGD, RMSProp, Adam, and so on.\n",
        "* ### __torch.multiprocessing :__ python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and hogwild training.\n",
        "* ### __torch.utils :__ DataLoader, Trainer and other utility functions for convenience\n",
        "* ### __torchvision :__ Consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
        "* ### __torchaudio:__ Consists of I/O, popular datasets and common audio transformations (oading sound files in the wav and mp3 format). \n",
        "* ### __torchtext:__ Consists of  data processing utilities and popular datasets for natural language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxfPpa7i3LCB"
      },
      "source": [
        "## __Importing modules and packages__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mwtPedQx3LCC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check that MPS is available\n",
        "if not torch.backends.mps.is_available():\n",
        "    if not torch.backends.mps.is_built():\n",
        "        print(\"MPS not available because the current PyTorch install was not \"\n",
        "              \"built with MPS enabled.\")\n",
        "    else:\n",
        "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
        "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
        "\n",
        "else:\n",
        "    mps_device = torch.device(\"mps\")\n",
        "\n",
        "    # Create a Tensor directly on the mps device\n",
        "    x = torch.ones(5, device=mps_device)\n",
        "    # Or\n",
        "    x = torch.ones(5, device=\"mps\")\n",
        "\n",
        "    # Any operation happens on the GPU\n",
        "    y = x * 2\n",
        "\n",
        "torch.backends.mps.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XpdGrah3LCC"
      },
      "source": [
        "## __Diffferent level of abstractions__ \n",
        "* ### __Tensor:__ Like array in Numpy, but runs on a GPU to accelerate computing\n",
        "* ### __Module:__ A neural network layer --> storing states or learnable weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZZXVLVf3LCC"
      },
      "source": [
        "## __Getting started with Tensors__ \n",
        "https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WNQCdKb3LCD"
      },
      "source": [
        "## Constructing tensor directly using torch makes the data type as (default data type):\n",
        "* ### 32-bit floating point\n",
        "* ### torch.float32 or torch.float\n",
        "* ### torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuh3HNd23LCD"
      },
      "source": [
        "## Construct a 5x3 matrix, uninitialized:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "quvHCmHF3LCE"
      },
      "outputs": [],
      "source": [
        "x = torch.empty(100, 3)\n",
        "\n",
        "x = torch.empty(5,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiY1UgNj3LCE",
        "outputId": "1e9a6d44-b503-46b2-f9fa-54d2a1d318b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XytSSOOP3LCF"
      },
      "source": [
        "## Construct a 2x3 matrix, uninitialized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZmogA9a3LCF",
        "outputId": "986bb9c1-6402-4046-cc02-45174d3f3b4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.Tensor(1)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_v8XVgr3LCF"
      },
      "source": [
        "## Construct a a randomly (uniform distribution on the interval [0, 1]) initialized $5\\times 3$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RJj9Qmu73LCF"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(5000,3000).to('mps')\n",
        "y =  torch.rand(3000,5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWIn-EWE3LCF",
        "outputId": "06368a1a-9634-4fdc-ef73-407b1bf010db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5906, 0.9272, 0.9428,  ..., 0.3035, 0.7183, 0.3241],\n",
              "        [0.6741, 0.1225, 0.6375,  ..., 0.3424, 0.2140, 0.0485],\n",
              "        [0.3202, 0.8774, 0.4583,  ..., 0.5721, 0.5567, 0.9984],\n",
              "        ...,\n",
              "        [0.0666, 0.2024, 0.7099,  ..., 0.7174, 0.2138, 0.4145],\n",
              "        [0.4680, 0.2087, 0.5580,  ..., 0.7760, 0.9784, 0.7293],\n",
              "        [0.2770, 0.7999, 0.6328,  ..., 0.7872, 0.4109, 0.1393]],\n",
              "       device='mps:0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_vjtc_e3LCF"
      },
      "source": [
        "## Construct a a randomly (Nomral distribution) initialized $5\\times 3$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdql2GZT3LCF",
        "outputId": "4e5dcd5a-9207-4e01-c2d8-5b0b179ce63e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7486, -0.3319, -0.5486],\n",
              "        [ 1.5538,  0.9944,  0.8574],\n",
              "        [ 2.0443, -0.0986,  0.6355],\n",
              "        [ 0.5049, -1.2381,  2.0815],\n",
              "        [-0.0403, -1.3926,  0.3176]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(5, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFDOGghg3LCG"
      },
      "source": [
        "## Construct a zero matrix and of dtype long:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.zeros(5, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0PW_OK-j3LCG"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNQy_pgt3LCG",
        "outputId": "e3b5ce00-2db8-4958-d0f1-ee415a17e995"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xHw2Xi3LCG"
      },
      "source": [
        "## Construct a tensor from data (a 3-d tensor):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nDiLTdrt3LCG"
      },
      "outputs": [],
      "source": [
        "y = torch.tensor([[[5.5, 3],[-3.8, 100]],[[1, 30],[023.8, 10]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrxSDgV83LCG",
        "outputId": "d36a7bd0-59a5-4468-95a0-83286a28cfdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61O2Orj63LCG"
      },
      "source": [
        "## The size or shape of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzxOw20R3LCG",
        "outputId": "03ac03d6-f1be-4007-8046-6477e58fd064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "****************************************\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x.size())\n",
        "print('*'*40)\n",
        "x.shape  # shape built-in method in Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-x1whac3LCG"
      },
      "source": [
        "## Construct a tensor based on an existing tensor:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv77JGQz3LCG"
      },
      "source": [
        "###  Creating a filled tensor \n",
        "* ### Any PyTorch method with an underscore (_) means an in-place operation (it modifies the content without creating a new object)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3TUQUd3LCG",
        "outputId": "ad65ad60-ef58-4dc5-b4fc-a275cb752d90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[5.],\n",
              "         [5.],\n",
              "         [5.]],\n",
              "\n",
              "        [[5.],\n",
              "         [5.],\n",
              "         [5.]],\n",
              "\n",
              "        [[5.],\n",
              "         [5.],\n",
              "         [5.]],\n",
              "\n",
              "        [[5.],\n",
              "         [5.],\n",
              "         [5.]]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.ones(4,3,1)\n",
        "x.fill_(5)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BViuQNEA3LCG"
      },
      "source": [
        "###  Reusing the properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
        "* ### Construcitng tensor from list makes data type as __torch.FloatTensor (float32)__ or __torch.Longtensor (signed int64)__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lulionR_vPwH",
        "outputId": "36f0ad9d-c746-4558-f027-85197042c5ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioiXkC7m3LCH",
        "outputId": "e4c4b9f2-1d3a-499b-b6db-9f34c7cd4ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]])\n",
            "****************************************\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "def describe(x):\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "    print(\"Shape/size: {}\".format(x.shape))\n",
        "    print(\"Values: \\n{}\".format(x))\n",
        "    \n",
        "c = [[1., 1., 1.]]*3\n",
        "c1 = torch.tensor(c)\n",
        "describe(c1)\n",
        "print('*'*40)\n",
        "\n",
        "cc = [[1, 1, 1]]*3\n",
        "cc1 = torch.tensor(cc)\n",
        "describe(cc1)\n",
        "print('*'*40)\n",
        "\n",
        "d = torch.ones((3,3))\n",
        "describe(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stPc6Q3K3LCH"
      },
      "source": [
        "### Changing the data type of a tensor in different ways:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DEjbjJ6D3LCH"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(1,5)\n",
        "y = torch.randn_like(x) \n",
        "z = torch.randn_like(x, dtype=torch.double) \n",
        "t = y.long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgHPM5D7v0nw",
        "outputId": "9c069178-0cbc-4abb-9430-8d75abe67d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[-0.5469,  0.1024, -0.8025, -0.8389, -0.6767]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "describe(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO03uq_M3LCH",
        "outputId": "044031fd-2f34-4ae3-d5d1-2663fbddfc11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[1., 1., 1., 1., 1.]])\n",
            "****************************************\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[ 0.9572, -1.1718,  0.8479,  0.5489,  0.2540]])\n",
            "****************************************\n",
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[-0.5469,  0.1024, -0.8025, -0.8389, -0.6767]], dtype=torch.float64)\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[ 0, -1,  0,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "print('*'*40)\n",
        "describe(y)\n",
        "print('*'*40)\n",
        "describe(z)\n",
        "print('*'*40)\n",
        "describe(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rqMCZ83LCH"
      },
      "source": [
        "# Getting started with Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIZX2Zbo3LCH"
      },
      "source": [
        "## Adding, subtracting,multiplying, deviding of two tensors (elementwise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5FADkF83LCH",
        "outputId": "c5c873c5-69b4-46af-cbf2-3b808eea3c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.5421,  1.3792,  0.4112],\n",
            "        [ 0.2263,  0.9741,  1.1715],\n",
            "        [ 0.0494, -0.1099,  1.4591],\n",
            "        [ 0.6836, -0.0480,  0.4073],\n",
            "        [ 0.7121,  1.1024,  1.7599]])\n",
            "tensor([[ 0.5421,  0.3792, -0.5888],\n",
            "        [-0.7737, -0.0259,  0.1715],\n",
            "        [-0.9506, -1.1099,  0.4591],\n",
            "        [-0.3164, -1.0480, -0.5927],\n",
            "        [-0.2879,  0.1024,  0.7599]])\n",
            "tensor([[ 0.5421,  0.3792, -0.5888],\n",
            "        [-0.7737, -0.0259,  0.1715],\n",
            "        [-0.9506, -1.1099,  0.4591],\n",
            "        [-0.3164, -1.0480, -0.5927],\n",
            "        [-0.2879,  0.1024,  0.7599]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(5,3)\n",
        "y = torch.ones(5,3)\n",
        "a = x + y\n",
        "print(a)\n",
        "b = x * y\n",
        "print(b)\n",
        "c = x/y\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm7SA6srwjjZ",
        "outputId": "a9125821-6057-466f-cd48-09fcf27d755b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.2400, 3.5542, 5.1143],\n",
              "        [2.3885, 2.8250, 2.1205],\n",
              "        [2.8200, 4.6905, 2.1010],\n",
              "        [3.8187, 1.2465, 4.3597],\n",
              "        [2.3025, 2.7341, 3.4818]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(5,3)\n",
        "y = torch.tensor([[2,3,4]])\n",
        "x + y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppq1Xb4NwwRd",
        "outputId": "616541eb-7fa0-43eb-efa7-24a61d6e0efb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.2400,  0.5542,  1.1143],\n",
              "        [ 0.3885, -0.1750, -1.8795],\n",
              "        [ 0.8200,  1.6905, -1.8990],\n",
              "        [ 1.8187, -1.7535,  0.3597],\n",
              "        [ 0.3025, -0.2659, -0.5182]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qyLyFRHp3LCH",
        "outputId": "f54fe0ae-9b7f-4f47-edd9-d74e1fbfc1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([5, 3])\n",
            "Values: \n",
            "tensor([[ 0.1200,  0.1847,  0.2786],\n",
            "        [ 0.1942, -0.0583, -0.4699],\n",
            "        [ 0.4100,  0.5635, -0.4747],\n",
            "        [ 0.9093, -0.5845,  0.0899],\n",
            "        [ 0.1513, -0.0886, -0.1295]])\n"
          ]
        }
      ],
      "source": [
        "torch.add(x, y)\n",
        "torch.sub(x, y)\n",
        "torch.mul(x, y)\n",
        "describe(torch.div(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3D5EoUw3LCH"
      },
      "source": [
        "## item() to get the value form a 0-rank tenser as a Python number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "phrqARqQ3LCH",
        "outputId": "65e82229-a553-4200-fece-83cf68994ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.9992])\n",
            "-1.9991884231567383\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ2AWXdl3LCH"
      },
      "source": [
        "### Reshaping a torch tensor using __view__ (buitl in function in torch), or using __reshape__ (built in method in Numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfRVHhjC3LCH",
        "outputId": "fe32abc9-220b-48b5-d15e-069fa347d174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([5, 2])\n",
            "Values: \n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([5, 2, 1, 1])\n",
            "Values: \n",
            "tensor([[[[0]],\n",
            "\n",
            "         [[1]]],\n",
            "\n",
            "\n",
            "        [[[2]],\n",
            "\n",
            "         [[3]]],\n",
            "\n",
            "\n",
            "        [[[4]],\n",
            "\n",
            "         [[5]]],\n",
            "\n",
            "\n",
            "        [[[6]],\n",
            "\n",
            "         [[7]]],\n",
            "\n",
            "\n",
            "        [[[8]],\n",
            "\n",
            "         [[9]]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(10)   ## similar to \"range\" in python\n",
        "y = x.view(5,2)\n",
        "z = x.reshape(5,2,1,1)\n",
        "describe(x)\n",
        "print('*'*40)\n",
        "describe(y)\n",
        "print('*'*40)\n",
        "describe(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ena6MbRk3LCH"
      },
      "source": [
        "### Applying to a specific dimension of a tensor\n",
        "* ### rows denote the dimention 0\n",
        "* ### columns denote the dimention 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQoB9CLa3LCI",
        "outputId": "4eab5838-982c-46b3-8eb8-d95405b47195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(12)\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([7, 5])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([5, 7])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "12\n",
            "****************************************\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[3,2],[4,3]])\n",
        "print(torch.sum(x))\n",
        "print('*'*40)\n",
        "describe(torch.sum(x, dim=0))\n",
        "print('*'*40)\n",
        "describe(torch.sum(x, dim=1))\n",
        "print('*'*40)\n",
        "describe(torch.sum(x))\n",
        "print('*'*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRpV_mNl3LCI"
      },
      "source": [
        "## Converting a Torch Tensor to a NumPy array and vice versa\n",
        "https://pytorch.org/docs/stable/notes/cuda.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yApsdj3E3LCI"
      },
      "source": [
        "### From Tensor to Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y91Ff4E83LCI"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(5)\n",
        "x = a.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9LSPr2e3LCI",
        "outputId": "2b765fd9-e63a-45da-97a4-fdc77692708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([5])\n",
            "Values: \n",
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "describe(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXa_HD2mybgW",
        "outputId": "a635ede4-8ff0-48d2-96e7-3c2fc7a6cd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMS-gsQ53LCI"
      },
      "source": [
        "### preserving the data type after converting to the numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "T0mGxgWA3LCI",
        "outputId": "b0d97f03-c54e-4b2a-bf72-c69d73f687ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsV452RL3LCI"
      },
      "source": [
        "### From Numpy to Tensor\n",
        "* ### Construcitng a tensor from a numpy array with float data type makes tensor data type as torch.DoubleTensor (float64)\n",
        "* ### Construcitng a tensor from a numpy array with integr data type makes tensor data type as torch.LongTensor (int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hs269zsk3LCI",
        "outputId": "d7f6fe30-1a25-4bf6-80dd-e8b17d229466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([5])\n",
            "Values: \n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "describe(b) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5ja0JhL3LCI"
      },
      "source": [
        "## Matrix inner product (similar to np.dot() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Ud_h423LCI",
        "outputId": "af7605ac-9580-4f5a-fc38-964b1ab8cd27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 1.3901,  0.2585, -0.2947],\n",
            "        [-5.6007, -1.7285,  3.5900]])\n",
            "****************************************\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[ 1.1214, -1.4503],\n",
            "        [-0.2655,  0.9652],\n",
            "        [ 0.5017,  1.5543]])\n",
            "****************************************  Using np.dot  ****************************************\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 1.3901323 ,  0.25847393, -0.2946853 ],\n",
              "       [-5.6007385 , -1.7284819 ,  3.5900083 ]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randn(2,3)\n",
        "b = torch.randn(3,3)\n",
        "describe(torch.mm(a,b))\n",
        "print('*'*40)\n",
        "describe(torch.mm(b, a.T))\n",
        "print('*'*40 + '  Using np.dot  ' + '*'*40)\n",
        "np.dot(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojA5zU3G3LCI"
      },
      "source": [
        "## Removing dimension with size 1 from a Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMh-q_Ti3LCI",
        "outputId": "55b5cef0-14f3-4cb2-c29f-f1c88d8a3fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 2])\n",
            "torch.Size([5, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(5,1,2)\n",
        "print(a.size())\n",
        "b = torch.squeeze(a, dim=0)\n",
        "print(b.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvfjMnac3LCJ"
      },
      "source": [
        "## Expanding dimension a Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9E8gu5n3LCJ",
        "outputId": "ac62c26c-6427-4892-e60e-85d40e9e08e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 1])\n",
            "torch.Size([5, 2, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(5,2,1)\n",
        "print(a.size())\n",
        "b = torch.unsqueeze(a, dim=2)\n",
        "print(b.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOJ4e8RK3LCJ"
      },
      "source": [
        "### Manipulating torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQZREYJ_3LCJ",
        "outputId": "5951969b-d65c-4609-d05b-4289e4f63ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, 2)\n",
        "x[:, 1] += 1\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odYCr-xq3LCJ"
      },
      "source": [
        "## Indexing, Slicing, and Joining (very familiar to Numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmrLNL5y3LCJ"
      },
      "source": [
        "* ### Simple indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL4B5hAw3LCJ",
        "outputId": "f45a960a-bf71-4c7e-c8bb-6d4d1da667ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "0\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "4\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "describe(x)\n",
        "print('*'*40)\n",
        "y = x[0, 0]\n",
        "describe(y)\n",
        "print('*'*40)\n",
        "z = x[1, 1]\n",
        "describe(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpqpdw4U3LCJ"
      },
      "source": [
        "* ### More complicated indexing settings (Indices __should__ be a LongTensor by default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oioiefOc3LCJ",
        "outputId": "f4c06b04-01cb-4876-e0fb-e59ffa80226a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 5])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 3, 4],\n",
            "        [5, 6, 7, 8, 9]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [5, 7]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [5, 7]])\n",
            "****************************************  Type of tensor indices_2  ****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 2])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 5])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 3, 4]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([2, 4])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(10).view(2, 5)\n",
        "describe(x)\n",
        "print('*'*40)\n",
        "indices_1 = torch.LongTensor([0, 2])\n",
        "y = torch.index_select(x, dim=1, index=indices_1)\n",
        "describe(y)\n",
        "print('*'*40)\n",
        "indices_2 = torch.from_numpy(np.array([0, 2]))\n",
        "z = torch.index_select(x, dim=1, index=indices_2)\n",
        "describe(z)\n",
        "print('*'*40 + '  Type of tensor indices_2  '+'*'*40 )\n",
        "describe(indices_2)\n",
        "print('*'*40)\n",
        "indices_3 = torch.LongTensor([0])\n",
        "t = torch.index_select(x, dim=0, index=indices_3)\n",
        "describe(t)\n",
        "print('*'*40)\n",
        "row_ind = torch.tensor([0]).long()\n",
        "col_ind = torch.LongTensor([2, 4])\n",
        "describe(x[row_ind, col_ind])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OevoRWki3LCJ"
      },
      "source": [
        "* ### Joining torch tensors using __torch.cat__ and __torch.stack__ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tGfjqNWy3LCJ",
        "outputId": "01bac80d-7837-4ac6-98bf-e2ec9e14e6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "****************************************\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2,3)\n",
        "describe(x)\n",
        "print('*'*40)\n",
        "describe(torch.cat((x,x), dim=1))\n",
        "print('*'*40)\n",
        "describe(torch.cat((x,x), dim=0))\n",
        "print('*'*40)\n",
        "describe(torch.stack((x, x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUysgrU_060X",
        "outputId": "5d3a9e28-2f71-4a31-be71-ee0c19118530"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 3])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(1,5,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSwVwFRv0nKV",
        "outputId": "5cd7a991-0875-431b-9917-9c0ce7a9f3d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZxP4f33LCJ"
      },
      "source": [
        "## CUDA Tensors and GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaYmm9g3LCJ"
      },
      "source": [
        "* ### Access to the GPUs is accomplished by an API called CUDA. \n",
        "* ### NVIDIA has created the CUDA API for only NVIDIA GPUs.\n",
        "* ### PyTorch offers CUDA tensor objects that are not different from the regular CPU-bound tensors except for end user.\n",
        "* ### Transfering Tensors to different devices, e.g., GPU, CPU using the __''.to''__ method.\n",
        "* ### To run on GPU, just cast tensors to a cuda data type!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nHJv65I3LCK"
      },
      "source": [
        "### First check if the CUDA interface exists on your system (__cuda.FloatTensor__ is a defualt data type for created toech tensors in GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Z8wiRyKc3LCK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    dtype = torch.cuda.FloatTensor         # casting tensors to a cuda data type\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrzLH8cr1XBU",
        "outputId": "8d180902-1e1e-4990-c0d1-1d08bc9c8576"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_9npF6B3LCK"
      },
      "source": [
        "### Directly create a tensor on GPU, or use strings ``.to(\"cuda\")``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9qQahaqN3LCK"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(b, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)  \n\u001b[0;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# or .to(y.device)\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "b = torch.ones(3,4)\n",
        "y = torch.ones_like(b, device='cpu', dtype=torch.float)  \n",
        "x = torch.randn(y.size()).to('cuda') # or .to(y.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "wKQkUoQD3LCK",
        "outputId": "50d77c4f-156e-4aec-d334-e058ebc4666e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a7554d7108d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "z = x + y\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IXyON7D3LCK"
      },
      "source": [
        "## AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
        "https://pytorch.org/docs/stable/autograd.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3IN8CDm3LCK"
      },
      "source": [
        "* ### Central to all neural networks in PyTorch is the autograd package.\n",
        "* ### Every Tensor has an attribute called __.requires_grad__ which can be True or False.\n",
        "* ### When it is True, starts to track all operations on it (bookkeeping).\n",
        "* ### When finishing the computation, one can call __.backward()__ and have all the gradients computed automatically\n",
        "* ### The gradient for the tensors will be accumulated into __.grad__ attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbjNGjC83LCK"
      },
      "source": [
        "### __To stop a tensor from tracking history:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfUexJKS3LCK"
      },
      "source": [
        "* ## First approach:\n",
        "###    - calling .detach() to detach it from the computation history\n",
        "###    - It also prevents future computation from being tracked\n",
        "\n",
        "* ## Second  approach:\n",
        "###   - wrap the code block using __with torch.no_grad()__ \n",
        "###   - Deactivating computation of the gradient for trainable parameters with __requires_grad=False__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am_wyFuo3LCK"
      },
      "source": [
        "## Each tensor has a .grad_fn attribute that references a Function that has created the Tensor \n",
        "(grad_fn is None for Tensors created by the user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3wAs5Wg3LCK",
        "outputId": "b32eef33-e90a-4cb9-ae74-fa6fc0ae69f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptkXp3K63LCK"
      },
      "source": [
        "### Operating a function on x makes the resulting tensor have __grad_fn__ attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi_oUZxT3LCK",
        "outputId": "0e4136d1-924f-409d-b335-a3a9fb5926e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = x + 2\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rKDdXX83LCK"
      },
      "source": [
        "### __requires_grad_(.)__ changes an existing Tensor’s requires_grad flag in-place. \n",
        "### The input flag defaults to False if not given"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElekpnWU3LCK",
        "outputId": "bdbbd8dc-b092-4ca0-de3d-623ec4e2f757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 1.],\n",
            "        [2., 3.]])\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(4).float().view(2,2)\n",
        "print(x)\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZcqowua3LCK",
        "outputId": "454c37b7-56d3-4cb5-f2a8-4a0c300cb559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFl6eEfy3LCK",
        "outputId": "2c0378b9-a29e-4fbb-c781-e4d2bdd36cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14., grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7fbac8507d90>\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "y = (x * x).sum()\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "print(y.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlhA_x3M3LCK"
      },
      "source": [
        "### The backward pass is started by using the __backward()__ method \n",
        "###  __backward()__ method operates on a tensor resulting from the evaluation of a loss function. \n",
        "### The backward pass calculates a gradient value for a tensor object that involved in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxHGpg3j3QHZ",
        "outputId": "b85b117a-8949-4b4e-991a-38fcf1d9052c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.]], requires_grad=True)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTi8rM1B3RSn",
        "outputId": "7bf3d01c-fcce-4164-cbf1-5dc850e82edb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [4., 9.]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djpwZRtF3LCL",
        "outputId": "1887516e-8242-4e0e-c993-acb14fe06807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14., grad_fn=<SumBackward0>)\n",
            "tensor([[ 0.,  8.],\n",
            "        [16., 24.]])\n",
            "(tensor([[0., 2.],\n",
            "        [4., 6.]]),)\n"
          ]
        }
      ],
      "source": [
        "# if x.grad is not None:\n",
        "#     x.grad.zero_() # comment this line will accumulate gradients\n",
        "\n",
        "out = (x * x).sum()\n",
        "out2 = out + 3\n",
        "#out2.backward()\n",
        "print(out)\n",
        "print(x.grad)\n",
        "x_grad = torch.autograd.grad(out,x)\n",
        "print(x_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9qvX0eL3LCL"
      },
      "source": [
        "### To explicitly compute gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3pxUvos3LCL",
        "outputId": "d9a8a75b-f921-48f3-a5fa-26d1f08fb794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.,  7.],\n",
            "        [12., 17.]], grad_fn=<AddBackward0>)\n",
            "(tensor([[ 20.,  70.],\n",
            "        [120., 170.]]),)\n"
          ]
        }
      ],
      "source": [
        "z = 5*x + 2\n",
        "print(z)\n",
        "out = (z* z).sum()\n",
        "x_grad = torch.autograd.grad(out,x)\n",
        "print(x_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh-3V-EBg7_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYyGbbqeg8PJ"
      },
      "source": [
        "#Simple ML model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZmJ2OuqLg-D7"
      },
      "outputs": [],
      "source": [
        "x1 = torch.randn(1000)\n",
        "x2 = torch.randn(1000) * 2 + 15\n",
        "y = x1**2 + x2\n",
        "\n",
        "data = torch.stack((x1,x2,y),dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT34mzcLjquG",
        "outputId": "f850a3f3-f239-40ea-f283-870da1b414cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1000, 3])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DBk1DFuOhUWP"
      },
      "outputs": [],
      "source": [
        "class net(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim=3):\n",
        "    '''\n",
        "    input_dim, output_dim:self-evident; \n",
        "    hidden_dim: all neural networks in this model are using the same hidden layer dimension for simplicity \n",
        "    '''\n",
        "    super().__init__()\n",
        "    \n",
        "    neuralnet = [nn.Linear(input_dim,hidden_dim),nn.ELU(),nn.Linear(hidden_dim, output_dim)]\n",
        "    self.neuralnet = nn.Sequential(*neuralnet)\n",
        "\n",
        "    \n",
        "  def forward(self,X):\n",
        "\n",
        "    y = self.neuralnet(X)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zYR1Lri8iSP0"
      },
      "outputs": [],
      "source": [
        "from torch.nn import MSELoss as MSE\n",
        "mse = MSE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_prEZTaYiVXy",
        "outputId": "a785e2d8-792f-4f2d-c608-782c9fbc1bd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "100%|██████████| 50/50 [00:00<00:00, 55.12it/s]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "#define a dataloader\n",
        "loader = DataLoader(data,batch_size=100, shuffle=True)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = net(input_dim=2, output_dim=1)\n",
        "EPOCHS = 50\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "MSE = []\n",
        "tqdm_epoch = tqdm.trange(EPOCHS)\n",
        "for _ in tqdm_epoch:\n",
        "  for tr in loader:  \n",
        "    X = tr[:,0:2]\n",
        "    y = tr[:,2]\n",
        "    optimizer.zero_grad()  \n",
        "    y_est = model(X)\n",
        "    loss =  mse(y_est,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  MSE.append(loss.detach().numpy())\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "QidCQoI4icoA",
        "outputId": "e77de688-55d4-40f1-b291-2b664a4e5b8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbac723f7d0>]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_N0D3jpkN6M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
