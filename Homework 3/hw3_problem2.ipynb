{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Optimizers from Scratch\n",
    "\n",
    "## 2.1 Optimizer Implementation\n",
    "\n",
    "### **Imports and Device Configuration**\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the device\n",
    "\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations: Convert images to tensors and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 64  # Initial batch size; will vary in 2.2\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Input channels=1 for MNIST\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 Max pooling\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # Convolutional layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # Flatten\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_Momentum:\n",
    "    def __init__(self, params, lr=0.01, beta=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.velocities = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is not None:\n",
    "                    # Update velocity\n",
    "                    self.velocities[i] = self.beta * self.velocities[i] + (1 - self.beta) * p.grad\n",
    "                    # Update parameters\n",
    "                    p.data -= self.lr * self.velocities[i]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAG:\n",
    "    def __init__(self, params, lr=0.01, beta=0.95):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.velocities = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is not None:\n",
    "                    prev_velocity = self.velocities[i]\n",
    "                    # Update velocity\n",
    "                    self.velocities[i] = self.beta * self.velocities[i] + p.grad\n",
    "                    # Update parameters\n",
    "                    p.data -= self.lr * (self.beta * prev_velocity + (1 - self.beta) * self.velocities[i])\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    def __init__(self, params, lr=0.001, beta=0.95, gamma=1.0, eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.squares = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is not None:\n",
    "                    # Update squared gradients\n",
    "                    self.squares[i] = self.beta * self.squares[i] + (1 - self.beta) * (p.grad ** 2)\n",
    "                    # Update parameters\n",
    "                    p.data -= self.lr * (p.grad / (self.squares[i].sqrt() + self.eps))\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]\n",
    "        self.t = 0  # Time step\n",
    "    \n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is not None:\n",
    "                    # Update biased first moment estimate\n",
    "                    self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * p.grad\n",
    "                    # Update biased second moment estimate\n",
    "                    self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (p.grad ** 2)\n",
    "                    # Compute bias-corrected first moment estimate\n",
    "                    m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "                    # Compute bias-corrected second moment estimate\n",
    "                    v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "                    # Update parameters\n",
    "                    p.data -= self.lr * m_hat / (v_hat.sqrt() + self.eps)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, num_epochs=10, l1_lambda=1e-5):\n",
    "    \"\"\"\n",
    "    Trains the CNN model using the provided optimizer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The CNN model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        test_loader (DataLoader): DataLoader for test data.\n",
    "        optimizer: Optimizer instance.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        l1_lambda (float): L1 regularization coefficient.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing training loss history, validation loss history, and validation accuracy history.\n",
    "    \"\"\"\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Lists to store losses and accuracies\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy_history = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # L1 Regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss += l1_lambda * l1_norm\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # L1 Regularization\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss += l1_lambda * l1_norm\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    return train_loss_history, val_loss_history, val_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Momentum Optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:19<00:00, 48.05batch/s, loss=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6748, Val Loss: 0.2399, Val Accuracy: 94.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:17<00:00, 52.15batch/s, loss=0.126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.2037, Val Loss: 0.1577, Val Accuracy: 96.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:18<00:00, 51.46batch/s, loss=0.127] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.1472, Val Loss: 0.1360, Val Accuracy: 97.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:18<00:00, 51.84batch/s, loss=0.0843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.1236, Val Loss: 0.1090, Val Accuracy: 97.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:18<00:00, 51.88batch/s, loss=0.14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.1099, Val Loss: 0.1040, Val Accuracy: 98.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:18<00:00, 50.86batch/s, loss=0.048] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.1011, Val Loss: 0.0937, Val Accuracy: 98.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:18<00:00, 51.58batch/s, loss=0.0738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0946, Val Loss: 0.0866, Val Accuracy: 98.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:18<00:00, 51.86batch/s, loss=0.0816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0895, Val Loss: 0.0898, Val Accuracy: 98.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:18<00:00, 51.58batch/s, loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0858, Val Loss: 0.0831, Val Accuracy: 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:18<00:00, 51.87batch/s, loss=0.0927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0817, Val Loss: 0.0831, Val Accuracy: 98.66%\n",
      "Momentum Optimizer Training Time: 193.50 seconds\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Momentum\n",
    "learning_rate_momentum = 0.01\n",
    "beta_momentum = 0.9\n",
    "batch_size_momentum = 64  # Adjust as needed\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader_momentum = DataLoader(dataset=train_dataset, batch_size=batch_size_momentum, shuffle=True, num_workers=0)\n",
    "test_loader_momentum = DataLoader(dataset=test_dataset, batch_size=batch_size_momentum, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model_momentum = CNNModel()\n",
    "optimizer_momentum = SGD_Momentum(model_momentum.parameters(), lr=learning_rate_momentum, beta=beta_momentum)\n",
    "\n",
    "print(\"Training with Momentum Optimizer\")\n",
    "start_time = time.time()\n",
    "train_loss_momentum, val_loss_momentum, val_acc_momentum = train_model(\n",
    "    model_momentum, train_loader_momentum, test_loader_momentum, optimizer_momentum, num_epochs=10, l1_lambda=1e-5)\n",
    "end_time = time.time()\n",
    "print(f\"Momentum Optimizer Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Nesterov's Accelerated Gradient (NAG) Optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:18<00:00, 51.40batch/s, loss=0.0856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.4008, Val Loss: 0.1189, Val Accuracy: 98.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:18<00:00, 51.14batch/s, loss=0.0641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.1185, Val Loss: 0.0934, Val Accuracy: 98.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:18<00:00, 51.53batch/s, loss=0.0557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0951, Val Loss: 0.0969, Val Accuracy: 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:18<00:00, 51.70batch/s, loss=0.261] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0819, Val Loss: 0.0845, Val Accuracy: 98.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:18<00:00, 51.54batch/s, loss=0.0504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0729, Val Loss: 0.0771, Val Accuracy: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:18<00:00, 51.59batch/s, loss=0.0729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0638, Val Loss: 0.0743, Val Accuracy: 99.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:18<00:00, 50.52batch/s, loss=0.0474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0572, Val Loss: 0.0725, Val Accuracy: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:18<00:00, 50.79batch/s, loss=0.039] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0541, Val Loss: 0.0748, Val Accuracy: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:18<00:00, 50.20batch/s, loss=0.0371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0510, Val Loss: 0.0717, Val Accuracy: 98.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:18<00:00, 50.84batch/s, loss=0.0341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0442, Val Loss: 0.0624, Val Accuracy: 99.16%\n",
      "NAG Optimizer Training Time: 194.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for NAG\n",
    "learning_rate_nag = 0.01\n",
    "beta_nag = 0.95\n",
    "batch_size_nag = 64  # Adjust as needed\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader_nag = DataLoader(dataset=train_dataset, batch_size=batch_size_nag, shuffle=True, num_workers=0)\n",
    "test_loader_nag = DataLoader(dataset=test_dataset, batch_size=batch_size_nag, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model_nag = CNNModel()\n",
    "optimizer_nag = NAG(model_nag.parameters(), lr=learning_rate_nag, beta=beta_nag)\n",
    "\n",
    "print(\"\\nTraining with Nesterov's Accelerated Gradient (NAG) Optimizer\")\n",
    "start_time = time.time()\n",
    "train_loss_nag, val_loss_nag, val_acc_nag = train_model(\n",
    "    model_nag, train_loader_nag, test_loader_nag, optimizer_nag, num_epochs=10, l1_lambda=1e-5)\n",
    "end_time = time.time()\n",
    "print(f\"NAG Optimizer Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with RMSprop Optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:17<00:00, 53.57batch/s, loss=0.0384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1814, Val Loss: 0.0668, Val Accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:17<00:00, 53.99batch/s, loss=0.0421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.0764, Val Loss: 0.0729, Val Accuracy: 98.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:17<00:00, 53.94batch/s, loss=0.0297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0629, Val Loss: 0.0612, Val Accuracy: 98.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:17<00:00, 53.95batch/s, loss=0.0284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0553, Val Loss: 0.0544, Val Accuracy: 99.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:17<00:00, 54.05batch/s, loss=0.0292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0505, Val Loss: 0.0525, Val Accuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:17<00:00, 53.90batch/s, loss=0.0274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0462, Val Loss: 0.0497, Val Accuracy: 99.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:17<00:00, 54.07batch/s, loss=0.0288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0437, Val Loss: 0.0543, Val Accuracy: 99.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:17<00:00, 54.08batch/s, loss=0.0277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0407, Val Loss: 0.0558, Val Accuracy: 99.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:17<00:00, 53.91batch/s, loss=0.0737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0394, Val Loss: 0.0504, Val Accuracy: 99.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:17<00:00, 53.79batch/s, loss=0.0231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0377, Val Loss: 0.0543, Val Accuracy: 99.04%\n",
      "RMSprop Optimizer Training Time: 184.43 seconds\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for RMSprop\n",
    "learning_rate_rmsprop = 0.001\n",
    "beta_rmsprop = 0.95\n",
    "gamma_rmsprop = 1.0\n",
    "eps_rmsprop = 1e-8\n",
    "batch_size_rmsprop = 64  # Adjust as needed\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader_rmsprop = DataLoader(dataset=train_dataset, batch_size=batch_size_rmsprop, shuffle=True, num_workers=0)\n",
    "test_loader_rmsprop = DataLoader(dataset=test_dataset, batch_size=batch_size_rmsprop, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model_rmsprop = CNNModel()\n",
    "optimizer_rmsprop = RMSprop(model_rmsprop.parameters(), lr=learning_rate_rmsprop, beta=beta_rmsprop, gamma=gamma_rmsprop, eps=eps_rmsprop)\n",
    "\n",
    "print(\"\\nTraining with RMSprop Optimizer\")\n",
    "start_time = time.time()\n",
    "train_loss_rmsprop, val_loss_rmsprop, val_acc_rmsprop = train_model(\n",
    "    model_rmsprop, train_loader_rmsprop, test_loader_rmsprop, optimizer_rmsprop, num_epochs=10, l1_lambda=1e-5)\n",
    "end_time = time.time()\n",
    "print(f\"RMSprop Optimizer Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Adam Optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:17<00:00, 52.49batch/s, loss=0.0871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1718, Val Loss: 0.0956, Val Accuracy: 98.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:17<00:00, 52.91batch/s, loss=0.0712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.0839, Val Loss: 0.0737, Val Accuracy: 98.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:17<00:00, 52.54batch/s, loss=0.0575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0718, Val Loss: 0.0820, Val Accuracy: 98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [03:23<00:00,  4.61batch/s, loss=0.0429]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0672, Val Loss: 0.0739, Val Accuracy: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:17<00:00, 53.73batch/s, loss=0.0697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0611, Val Loss: 0.0687, Val Accuracy: 99.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [08:04<00:00,  1.94batch/s, loss=0.533]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0565, Val Loss: 0.0778, Val Accuracy: 98.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:17<00:00, 54.49batch/s, loss=0.048] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0549, Val Loss: 0.0693, Val Accuracy: 99.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:17<00:00, 54.94batch/s, loss=0.039] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0536, Val Loss: 0.0687, Val Accuracy: 99.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:32<00:00, 29.15batch/s, loss=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0474, Val Loss: 0.0632, Val Accuracy: 99.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:17<00:00, 54.51batch/s, loss=0.0357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0458, Val Loss: 0.0632, Val Accuracy: 99.22%\n",
      "Adam Optimizer Training Time: 852.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Adam\n",
    "learning_rate_adam = 0.001\n",
    "beta1_adam = 0.9\n",
    "beta2_adam = 0.999\n",
    "eps_adam = 1e-8\n",
    "batch_size_adam = 64  # Adjust as needed\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader_adam = DataLoader(dataset=train_dataset, batch_size=batch_size_adam, shuffle=True, num_workers=0)\n",
    "test_loader_adam = DataLoader(dataset=test_dataset, batch_size=batch_size_adam, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model_adam = CNNModel()\n",
    "optimizer_adam = Adam(model_adam.parameters(), lr=learning_rate_adam, beta1=beta1_adam, beta2=beta2_adam, eps=eps_adam)\n",
    "\n",
    "print(\"\\nTraining with Adam Optimizer\")\n",
    "start_time = time.time()\n",
    "train_loss_adam, val_loss_adam, val_acc_adam = train_model(\n",
    "    model_adam, train_loader_adam, test_loader_adam, optimizer_adam, num_epochs=10, l1_lambda=1e-5)\n",
    "end_time = time.time()\n",
    "print(f\"Adam Optimizer Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Validation Accuracies:\n",
      "Momentum Optimizer:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m64\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     acc \u001b[38;5;241m=\u001b[39m val_acc_momentum\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNesterov\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Accelerated Gradient Optimizer:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m64\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Validation Accuracies:\")\n",
    "\n",
    "print(\"Momentum Optimizer:\")\n",
    "for batch_size in [64]:\n",
    "    acc = val_acc_momentum\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nNesterov's Accelerated Gradient Optimizer:\")\n",
    "for batch_size in [64]:\n",
    "    acc = val_acc_nag\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nRMSprop Optimizer:\")\n",
    "for batch_size in [64]:\n",
    "    acc = val_acc_rmsprop\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nAdam Optimizer:\")\n",
    "for batch_size in [64]:\n",
    "    acc = val_acc_adam\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4, 8, 16, 32]\n",
    "\n",
    "def compare_optimizers(optimizer_class, optimizer_name, batch_sizes, learning_rate, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains the CNN model using a specific optimizer across different batch sizes.\n",
    "\n",
    "    Args:\n",
    "        optimizer_class: The optimizer class to instantiate.\n",
    "        optimizer_name (str): Name of the optimizer for display.\n",
    "        batch_sizes (list): List of batch sizes to test.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        **kwargs: Additional hyperparameters for the optimizer.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing training and validation losses and accuracies for each batch size.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\nTraining with {optimizer_name}, Batch Size: {batch_size}\")\n",
    "        # Define DataLoaders\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Initialize model and optimizer\n",
    "        model = CNNModel()\n",
    "        optimizer = optimizer_class(model.parameters(), lr=learning_rate, **kwargs)\n",
    "        \n",
    "        # Train the model\n",
    "        train_loss, val_loss, val_acc = train_model(\n",
    "            model, train_loader, test_loader, optimizer, num_epochs=10, l1_lambda=1e-5)\n",
    "        \n",
    "        # Store the results\n",
    "        results[batch_size] = {\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Momentum, Batch Size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 15000/15000 [00:53<00:00, 280.09batch/s, loss=0.0604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1888, Val Loss: 0.0906, Val Accuracy: 98.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 15000/15000 [01:12<00:00, 207.11batch/s, loss=0.0671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.0882, Val Loss: 0.0760, Val Accuracy: 98.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 15000/15000 [01:11<00:00, 209.43batch/s, loss=0.0399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0708, Val Loss: 0.0837, Val Accuracy: 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 15000/15000 [01:11<00:00, 211.20batch/s, loss=0.0387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0607, Val Loss: 0.0840, Val Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 15000/15000 [01:12<00:00, 208.09batch/s, loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0529, Val Loss: 0.0804, Val Accuracy: 98.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 15000/15000 [01:13<00:00, 204.89batch/s, loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0487, Val Loss: 0.0625, Val Accuracy: 99.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 15000/15000 [01:12<00:00, 207.43batch/s, loss=0.0308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0431, Val Loss: 0.0555, Val Accuracy: 99.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 15000/15000 [01:21<00:00, 184.56batch/s, loss=0.0288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0397, Val Loss: 0.0611, Val Accuracy: 99.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 15000/15000 [01:27<00:00, 170.93batch/s, loss=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0371, Val Loss: 0.0569, Val Accuracy: 99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 15000/15000 [01:45<00:00, 141.66batch/s, loss=0.0261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0350, Val Loss: 0.0521, Val Accuracy: 99.25%\n",
      "\n",
      "Training with Momentum, Batch Size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 7500/7500 [00:47<00:00, 159.21batch/s, loss=0.0481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.2227, Val Loss: 0.0975, Val Accuracy: 98.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 7500/7500 [00:46<00:00, 162.79batch/s, loss=0.343] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.0987, Val Loss: 0.0944, Val Accuracy: 98.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 7500/7500 [00:46<00:00, 159.62batch/s, loss=0.0468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0808, Val Loss: 0.0695, Val Accuracy: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 7500/7500 [00:47<00:00, 159.05batch/s, loss=0.042] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0701, Val Loss: 0.0702, Val Accuracy: 99.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 7500/7500 [00:46<00:00, 160.47batch/s, loss=0.0426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0635, Val Loss: 0.0612, Val Accuracy: 99.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 7500/7500 [00:47<00:00, 158.37batch/s, loss=0.0379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0574, Val Loss: 0.0685, Val Accuracy: 99.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 7500/7500 [00:47<00:00, 158.34batch/s, loss=0.0389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0534, Val Loss: 0.0751, Val Accuracy: 98.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 7500/7500 [00:47<00:00, 156.79batch/s, loss=0.0369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0489, Val Loss: 0.0601, Val Accuracy: 99.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 7500/7500 [00:47<00:00, 157.53batch/s, loss=0.0334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0455, Val Loss: 0.0638, Val Accuracy: 99.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 7500/7500 [00:47<00:00, 158.42batch/s, loss=0.0339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0418, Val Loss: 0.0582, Val Accuracy: 99.23%\n",
      "\n",
      "Training with Momentum, Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3750/3750 [00:37<00:00, 98.91batch/s, loss=0.241]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.3061, Val Loss: 0.1234, Val Accuracy: 97.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3750/3750 [00:38<00:00, 97.69batch/s, loss=0.071]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.1152, Val Loss: 0.0954, Val Accuracy: 98.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3750/3750 [01:08<00:00, 54.74batch/s, loss=0.0442] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0930, Val Loss: 0.0847, Val Accuracy: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3750/3750 [01:26<00:00, 43.12batch/s, loss=0.0436] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0821, Val Loss: 0.0757, Val Accuracy: 98.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3750/3750 [00:56<00:00, 66.40batch/s, loss=0.0435] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0749, Val Loss: 0.0732, Val Accuracy: 98.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3750/3750 [00:49<00:00, 75.72batch/s, loss=0.0414] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0691, Val Loss: 0.0734, Val Accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3750/3750 [00:42<00:00, 89.09batch/s, loss=0.0948] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0637, Val Loss: 0.0662, Val Accuracy: 99.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3750/3750 [01:34<00:00, 39.80batch/s, loss=0.0475] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0595, Val Loss: 0.0701, Val Accuracy: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3750/3750 [00:38<00:00, 98.56batch/s, loss=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0561, Val Loss: 0.0649, Val Accuracy: 99.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3750/3750 [00:41<00:00, 89.60batch/s, loss=0.048]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0533, Val Loss: 0.0643, Val Accuracy: 99.16%\n",
      "\n",
      "Training with Momentum, Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1875/1875 [01:35<00:00, 19.68batch/s, loss=0.082] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.4024, Val Loss: 0.1700, Val Accuracy: 96.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1875/1875 [00:28<00:00, 65.26batch/s, loss=0.22]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.1416, Val Loss: 0.1145, Val Accuracy: 97.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1875/1875 [00:28<00:00, 66.73batch/s, loss=0.0864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.1126, Val Loss: 0.1156, Val Accuracy: 97.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1875/1875 [00:42<00:00, 43.94batch/s, loss=0.0755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0990, Val Loss: 0.0886, Val Accuracy: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1875/1875 [00:52<00:00, 35.77batch/s, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0891, Val Loss: 0.0880, Val Accuracy: 98.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1875/1875 [00:30<00:00, 62.36batch/s, loss=0.142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0824, Val Loss: 0.0836, Val Accuracy: 98.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1875/1875 [00:53<00:00, 35.08batch/s, loss=0.0471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0771, Val Loss: 0.0761, Val Accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1875/1875 [04:45<00:00,  6.56batch/s, loss=0.0991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0735, Val Loss: 0.0746, Val Accuracy: 98.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1875/1875 [00:28<00:00, 65.52batch/s, loss=0.0429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0694, Val Loss: 0.0721, Val Accuracy: 98.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1875/1875 [00:27<00:00, 67.18batch/s, loss=0.0476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0659, Val Loss: 0.0806, Val Accuracy: 98.71%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Momentum\n",
    "learning_rate_momentum = 0.01\n",
    "beta_momentum = 0.9\n",
    "\n",
    "momentum_results = compare_optimizers(\n",
    "    optimizer_class=SGD_Momentum,\n",
    "    optimizer_name=\"Momentum\",\n",
    "    batch_sizes=batch_sizes,\n",
    "    learning_rate=learning_rate_momentum,\n",
    "    beta=beta_momentum\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Nesterov's Accelerated Gradient, Batch Size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 15000/15000 [04:16<00:00, 58.53batch/s, loss=2.42]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 2.1128, Val Loss: 2.3843, Val Accuracy: 11.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 15000/15000 [01:17<00:00, 193.23batch/s, loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 2.3748, Val Loss: 2.3628, Val Accuracy: 10.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 15000/15000 [01:17<00:00, 192.80batch/s, loss=2.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 2.3622, Val Loss: 2.3630, Val Accuracy: 8.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 15000/15000 [01:23<00:00, 179.77batch/s, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 2.3537, Val Loss: 2.3472, Val Accuracy: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 15000/15000 [01:30<00:00, 165.13batch/s, loss=2.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 2.3484, Val Loss: 2.3525, Val Accuracy: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 15000/15000 [01:16<00:00, 197.26batch/s, loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 2.3442, Val Loss: 2.3350, Val Accuracy: 10.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 15000/15000 [01:16<00:00, 197.34batch/s, loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 2.3392, Val Loss: 2.3325, Val Accuracy: 10.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 15000/15000 [01:18<00:00, 190.76batch/s, loss=2.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 2.3358, Val Loss: 2.3391, Val Accuracy: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 15000/15000 [04:20<00:00, 57.55batch/s, loss=2.36]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 2.3335, Val Loss: 2.3281, Val Accuracy: 10.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 15000/15000 [01:17<00:00, 193.49batch/s, loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 2.3312, Val Loss: 2.3256, Val Accuracy: 10.28%\n",
      "\n",
      "Training with Nesterov's Accelerated Gradient, Batch Size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 7500/7500 [00:45<00:00, 165.09batch/s, loss=0.223] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.4396, Val Loss: 0.3415, Val Accuracy: 92.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 7500/7500 [00:45<00:00, 163.05batch/s, loss=0.0569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.2783, Val Loss: 0.3359, Val Accuracy: 92.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 7500/7500 [00:46<00:00, 160.52batch/s, loss=0.0741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.2601, Val Loss: 0.2862, Val Accuracy: 94.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 7500/7500 [00:44<00:00, 170.19batch/s, loss=0.48]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.2716, Val Loss: 0.2774, Val Accuracy: 94.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 7500/7500 [00:49<00:00, 152.69batch/s, loss=0.0711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.3022, Val Loss: 0.3091, Val Accuracy: 95.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 7500/7500 [00:46<00:00, 160.54batch/s, loss=0.705] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.3411, Val Loss: 0.2805, Val Accuracy: 95.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 7500/7500 [00:49<00:00, 152.04batch/s, loss=0.0764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.2867, Val Loss: 0.3089, Val Accuracy: 95.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 7500/7500 [00:46<00:00, 161.69batch/s, loss=0.71]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.2868, Val Loss: 0.3503, Val Accuracy: 93.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 7500/7500 [00:47<00:00, 158.08batch/s, loss=0.451] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.3869, Val Loss: 0.2825, Val Accuracy: 95.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 7500/7500 [00:46<00:00, 162.26batch/s, loss=0.0964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.4721, Val Loss: 0.4419, Val Accuracy: 92.85%\n",
      "\n",
      "Training with Nesterov's Accelerated Gradient, Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3750/3750 [00:38<00:00, 96.90batch/s, loss=0.164]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.2983, Val Loss: 0.1569, Val Accuracy: 97.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3750/3750 [00:38<00:00, 98.26batch/s, loss=0.0586] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.1352, Val Loss: 0.1027, Val Accuracy: 98.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3750/3750 [00:38<00:00, 96.94batch/s, loss=0.0724] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.1162, Val Loss: 0.1711, Val Accuracy: 96.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3750/3750 [00:38<00:00, 96.80batch/s, loss=0.09]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.1012, Val Loss: 0.1003, Val Accuracy: 98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3750/3750 [00:38<00:00, 96.43batch/s, loss=0.0397] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0951, Val Loss: 0.1120, Val Accuracy: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3750/3750 [00:38<00:00, 97.95batch/s, loss=0.0512] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0982, Val Loss: 0.1013, Val Accuracy: 98.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3750/3750 [00:38<00:00, 96.35batch/s, loss=0.0574] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0972, Val Loss: 0.1097, Val Accuracy: 98.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3750/3750 [00:38<00:00, 97.16batch/s, loss=0.116]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0995, Val Loss: 0.1051, Val Accuracy: 98.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3750/3750 [00:40<00:00, 92.04batch/s, loss=0.0424] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0960, Val Loss: 0.1135, Val Accuracy: 98.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3750/3750 [00:42<00:00, 88.63batch/s, loss=0.0421] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0975, Val Loss: 0.1227, Val Accuracy: 98.30%\n",
      "\n",
      "Training with Nesterov's Accelerated Gradient, Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1875/1875 [00:28<00:00, 65.71batch/s, loss=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.3108, Val Loss: 0.1197, Val Accuracy: 97.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1875/1875 [00:29<00:00, 62.66batch/s, loss=0.0543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.1104, Val Loss: 0.0910, Val Accuracy: 98.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1875/1875 [00:32<00:00, 57.33batch/s, loss=0.0768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0867, Val Loss: 0.0924, Val Accuracy: 98.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1875/1875 [00:29<00:00, 62.64batch/s, loss=0.0386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0714, Val Loss: 0.0735, Val Accuracy: 98.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1875/1875 [00:29<00:00, 64.30batch/s, loss=0.0616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0616, Val Loss: 0.0781, Val Accuracy: 98.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1875/1875 [00:31<00:00, 58.79batch/s, loss=0.0351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0588, Val Loss: 0.0707, Val Accuracy: 98.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1875/1875 [00:30<00:00, 61.18batch/s, loss=0.0356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0526, Val Loss: 0.0720, Val Accuracy: 98.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1875/1875 [00:30<00:00, 61.58batch/s, loss=0.0316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0499, Val Loss: 0.0686, Val Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1875/1875 [00:31<00:00, 59.66batch/s, loss=0.0303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0464, Val Loss: 0.0754, Val Accuracy: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1875/1875 [00:31<00:00, 60.32batch/s, loss=0.0625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0437, Val Loss: 0.0690, Val Accuracy: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for NAG\n",
    "learning_rate_nag = 0.01\n",
    "beta_nag = 0.95\n",
    "\n",
    "nag_results = compare_optimizers(\n",
    "    optimizer_class=NAG,\n",
    "    optimizer_name=\"Nesterov's Accelerated Gradient\",\n",
    "    batch_sizes=batch_sizes,\n",
    "    learning_rate=learning_rate_nag,\n",
    "    beta=beta_nag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with RMSprop, Batch Size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 15000/15000 [01:21<00:00, 184.24batch/s, loss=0.0253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1449, Val Loss: 0.0791, Val Accuracy: 98.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  36%|███▌      | 5401/15000 [00:28<00:51, 186.65batch/s, loss=0.0218]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m gamma_rmsprop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m      5\u001b[0m eps_rmsprop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[0;32m----> 7\u001b[0m rmsprop_results \u001b[38;5;241m=\u001b[39m compare_optimizers(\n\u001b[1;32m      8\u001b[0m     optimizer_class\u001b[38;5;241m=\u001b[39mRMSprop,\n\u001b[1;32m      9\u001b[0m     optimizer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSprop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     batch_sizes\u001b[38;5;241m=\u001b[39mbatch_sizes,\n\u001b[1;32m     11\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate_rmsprop,\n\u001b[1;32m     12\u001b[0m     beta\u001b[38;5;241m=\u001b[39mbeta_rmsprop,\n\u001b[1;32m     13\u001b[0m     gamma\u001b[38;5;241m=\u001b[39mgamma_rmsprop,\n\u001b[1;32m     14\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps_rmsprop\n\u001b[1;32m     15\u001b[0m )\n",
      "Cell \u001b[0;32mIn[68], line 29\u001b[0m, in \u001b[0;36mcompare_optimizers\u001b[0;34m(optimizer_class, optimizer_name, batch_sizes, learning_rate, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizer_class(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m train_loss, val_loss, val_acc \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m     30\u001b[0m     model, train_loader, test_loader, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, l1_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Store the results\u001b[39;00m\n\u001b[1;32m     33\u001b[0m results[batch_size] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loss,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: val_acc\n\u001b[1;32m     37\u001b[0m }\n",
      "Cell \u001b[0;32mIn[62], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, num_epochs, l1_lambda)\u001b[0m\n\u001b[1;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 49\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Calculate average training loss\u001b[39;00m\n\u001b[1;32m     52\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1431\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m   1429\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay()\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[1;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 459\u001b[0m     fp_write(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m s \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m len_s, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:453\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m    452\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[0;32m--> 453\u001b[0m     fp_flush()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/iostream.py:578\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters for RMSprop\n",
    "learning_rate_rmsprop = 0.001\n",
    "beta_rmsprop = 0.95\n",
    "gamma_rmsprop = 1.0\n",
    "eps_rmsprop = 1e-8\n",
    "\n",
    "rmsprop_results = compare_optimizers(\n",
    "    optimizer_class=RMSprop,\n",
    "    optimizer_name=\"RMSprop\",\n",
    "    batch_sizes=batch_sizes,\n",
    "    learning_rate=learning_rate_rmsprop,\n",
    "    beta=beta_rmsprop,\n",
    "    gamma=gamma_rmsprop,\n",
    "    eps=eps_rmsprop\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Adam\n",
    "learning_rate_adam = 0.001\n",
    "beta1_adam = 0.9\n",
    "beta2_adam = 0.999\n",
    "eps_adam = 1e-8\n",
    "\n",
    "adam_results = compare_optimizers(\n",
    "    optimizer_class=Adam,\n",
    "    optimizer_name=\"Adam\",\n",
    "    batch_sizes=batch_sizes,\n",
    "    learning_rate=learning_rate_adam,\n",
    "    beta1=beta1_adam,\n",
    "    beta2=beta2_adam,\n",
    "    eps=eps_adam\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(optimizer_results, optimizer_name):\n",
    "    for batch_size, result in optimizer_results.items():\n",
    "        epochs = range(1, len(result['train_loss']) + 1)\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot Training and Validation Loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, result['train_loss'], 'b-', label='Training Loss')\n",
    "        plt.plot(epochs, result['val_loss'], 'r-', label='Validation Loss')\n",
    "        plt.title(f'{optimizer_name} - Batch Size {batch_size}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Validation Accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, result['val_accuracy'], 'g-', label='Validation Accuracy')\n",
    "        plt.title(f'{optimizer_name} - Batch Size {batch_size}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting Results for Momentum Optimizer\")\n",
    "plot_results(momentum_results, \"Momentum\")\n",
    "\n",
    "print(\"\\nPlotting Results for Nesterov's Accelerated Gradient Optimizer\")\n",
    "plot_results(nag_results, \"Nesterov's Accelerated Gradient\")\n",
    "\n",
    "print(\"\\nPlotting Results for RMSprop Optimizer\")\n",
    "plot_results(rmsprop_results, \"RMSprop\")\n",
    "\n",
    "print(\"\\nPlotting Results for Adam Optimizer\")\n",
    "plot_results(adam_results, \"Adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFinal Validation Accuracies:\")\n",
    "\n",
    "print(\"Momentum Optimizer:\")\n",
    "for batch_size in batch_sizes:\n",
    "    acc = momentum_results[batch_size]['val_accuracy'][-1]\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nNesterov's Accelerated Gradient Optimizer:\")\n",
    "for batch_size in batch_sizes:\n",
    "    acc = nag_results[batch_size]['val_accuracy'][-1]\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nRMSprop Optimizer:\")\n",
    "for batch_size in batch_sizes:\n",
    "    acc = rmsprop_results[batch_size]['val_accuracy'][-1]\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nAdam Optimizer:\")\n",
    "for batch_size in batch_sizes:\n",
    "    acc = adam_results[batch_size]['val_accuracy'][-1]\n",
    "    print(f\"Batch Size {batch_size}: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
